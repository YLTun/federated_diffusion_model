{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:37.293710Z",
     "start_time": "2023-05-12T06:14:37.287238Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:37.297544Z",
     "start_time": "2023-05-12T06:14:37.295327Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:37.920968Z",
     "start_time": "2023-05-12T06:14:37.298524Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:38.366499Z",
     "start_time": "2023-05-12T06:14:37.922031Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "\n",
    "from training import get_config, ImgDataset\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:38.371442Z",
     "start_time": "2023-05-12T06:14:38.368171Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fid_score(test_loader, gen_loader, feature_dim=2048):\n",
    "    fid_metric = FrechetInceptionDistance(feature=feature_dim, normalize=True).to(device)\n",
    "\n",
    "    for (x_test, _) in tqdm(test_loader):\n",
    "        x_test = x_test.to(device)\n",
    "        # x_test= x_test.type(torch.uint8)\n",
    "        fid_metric.update(x_test, real=True)\n",
    "\n",
    "    for (x_gen, _) in tqdm(gen_loader):\n",
    "        x_gen = x_gen.to(device)\n",
    "        # x_gen= x_gen.type(torch.uint8)\n",
    "        fid_metric.update(x_gen, real=False)\n",
    "\n",
    "    fid_score = fid_metric.compute()\n",
    "    return fid_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:39.543890Z",
     "start_time": "2023-05-12T06:14:38.373528Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yelintun/anaconda3/envs/diffusion_env/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "inception_metric = InceptionScore()\n",
    "\n",
    "def get_inception_score(gen_loader):\n",
    "    inception_metric = InceptionScore(normalize=True).to(device)\n",
    "    \n",
    "    for (x_gen, _) in tqdm(gen_loader):\n",
    "        x_gen = x_gen.to(device)\n",
    "        inception_metric.update(x_gen)\n",
    "        \n",
    "    inception_score = inception_metric.compute()\n",
    "    return inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T01:56:14.391863Z",
     "start_time": "2023-05-09T01:56:14.127260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_size': 32, 'channels': 3, 'batch_size': 512, 'train_transform': Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Resize(size=32, interpolation=bilinear, max_size=None, antialias=None)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      "), 'test_transform': Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=32, interpolation=bilinear, max_size=None, antialias=None)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")}\n",
      "{'lr': 0.0002, 'timesteps': 300, 'epochs': 1500, 'rounds': 300, 'local_epochs': 5, 'ema_decay': 0.998, 'eta': 1.0, 'save_interval': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define dataset.\n",
    "# dataset_name = 'cifar_10'\n",
    "# dataset_name = 'fashion_mnist'\n",
    "dataset_name = 'svhn'\n",
    "\n",
    "data_config, train_config = get_config(dataset_name)\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "\n",
    "# Data config.\n",
    "batch_size = 96\n",
    "test_transform = data_config['test_transform']\n",
    "\n",
    "# Training config.\n",
    "timesteps = train_config['timesteps']\n",
    "eta = train_config['eta']\n",
    "\n",
    "data_dir = os.path.join('../datasets/', dataset_name)\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "train_data = ImgDataset(train_dir, transform=test_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_data = ImgDataset(test_dir, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T08:42:00.597514Z",
     "start_time": "2023-05-01T08:38:28.030968Z"
    }
   },
   "outputs": [],
   "source": [
    "centralized_gen_dir = os.path.join('./output/diffusion_cen/', dataset_name, 'generated_img')\n",
    "centralized_gen_data = ImgDataset(centralized_gen_dir, transform=test_transform)\n",
    "centralized_gen_loader = torch.utils.data.DataLoader(centralized_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "cen_fid_score = get_fid_score(train_loader, centralized_gen_loader)\n",
    "print(cen_fid_score)\n",
    "print('{:.2f}'.format(cen_fid_score))\n",
    "\n",
    "cen_fid_score = get_fid_score(test_loader, centralized_gen_loader)\n",
    "print(cen_fid_score)\n",
    "print('{:.2f}'.format(cen_fid_score))\n",
    "\n",
    "cen_inception_score = get_inception_score(centralized_gen_loader)\n",
    "print(cen_inception_score)\n",
    "(mean, std) = cen_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T01:58:12.682184Z",
     "start_time": "2023-05-09T01:56:17.470977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/diffusion_fedavg/fashion_mnist_b_5_c_10_le_5/generated_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 625/625 [01:07<00:00,  9.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 105/105 [00:12<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.5763, device='cuda:0')\n",
      "15.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 105/105 [00:12<00:00,  8.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 105/105 [00:12<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.5783, device='cuda:0')\n",
      "16.58\n"
     ]
    }
   ],
   "source": [
    "beta = 5                     # 5, 0.5, 0.1              \n",
    "num_clients = 10               # 10, 30, 50\n",
    "num_local_epochs = 5           # 1, 5, 10\n",
    "\n",
    "fedavg_gen_dir = os.path.join('./output/diffusion_fedavg/', '{}_b_{}_c_{}_le_{}'.format(dataset_name, beta, num_clients, num_local_epochs), 'generated_img')\n",
    "print(fedavg_gen_dir)\n",
    "fedavg_gen_data = ImgDataset(fedavg_gen_dir, transform=test_transform)\n",
    "fedavg_gen_loader = torch.utils.data.DataLoader(fedavg_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "fedavg_train_fid_score = get_fid_score(train_loader, fedavg_gen_loader)\n",
    "print(fedavg_train_fid_score)\n",
    "print('{:.2f}'.format(fedavg_train_fid_score))\n",
    "\n",
    "fedavg_test_fid_score = get_fid_score(test_loader, fedavg_gen_loader)\n",
    "print(fedavg_test_fid_score)\n",
    "print('{:.2f}'.format(fedavg_test_fid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T01:59:22.856663Z",
     "start_time": "2023-05-09T01:59:10.849638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 105/105 [00:11<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(3.9339, device='cuda:0'), tensor(0.0819, device='cuda:0'))\n",
      "mean: 3.93, std: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fedavg_inception_score = get_inception_score(fedavg_gen_loader)\n",
    "print(fedavg_inception_score)\n",
    "(mean, std) = fedavg_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:38:26.958681Z",
     "start_time": "2023-03-23T02:38:26.952203Z"
    }
   },
   "outputs": [],
   "source": [
    "# imgs_dist1 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "# imgs_dist2 = torch.randint(100, 255, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "\n",
    "# imgs_dist1 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "# imgs_dist2 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8).to(device)\n",
    "\n",
    "# fid = FrechetInceptionDistance(feature=64).to(device)\n",
    "# fid.update(imgs_dist1, real=True)\n",
    "# fid.update(imgs_dist2, real=False)\n",
    "# fid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T01:14:32.626920Z",
     "start_time": "2023-04-06T01:14:32.624198Z"
    }
   },
   "outputs": [],
   "source": [
    "# FrechetInceptionDistance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:14:45.455757Z",
     "start_time": "2023-05-12T06:14:45.440598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_size': 64, 'channels': 3, 'batch_size': 128, 'train_transform': Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    Normalize(mean=[0.5], std=[0.5])\n",
      ")}\n",
      "{'lr': 0.0002, 'timesteps': 300, 'epochs': 1500, 'rounds': 300, 'local_epochs': 5, 'ema_decay': 0.998, 'eta': 1.0, 'save_interval': 100}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'sars_cov_2_ct_scan'\n",
    "\n",
    "data_config, train_config = get_config(dataset_name)\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "\n",
    "# Data config.\n",
    "batch_size = 96\n",
    "train_transform = data_config['train_transform']\n",
    "\n",
    "# Training config.\n",
    "timesteps = train_config['timesteps']\n",
    "eta = train_config['eta']\n",
    "\n",
    "data_dir = os.path.join('../datasets/', dataset_name)\n",
    "\n",
    "train_dir = os.path.join(data_dir)\n",
    "train_data = ImgDataset(train_dir, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:16:38.102173Z",
     "start_time": "2023-05-12T06:15:46.360306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  6.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48.1661, device='cuda:0')\n",
      "48.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.7201, device='cuda:0'), tensor(0.0382, device='cuda:0'))\n",
      "mean: 1.72, std: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "centralized_gen_dir = os.path.join('./output/diffusion_cen/', dataset_name, 'generated_img')\n",
    "centralized_gen_data = ImgDataset(centralized_gen_dir, transform=train_transform)\n",
    "centralized_gen_loader = torch.utils.data.DataLoader(centralized_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "cen_fid_score = get_fid_score(train_loader, centralized_gen_loader)\n",
    "print(cen_fid_score)\n",
    "print('{:.2f}'.format(cen_fid_score))\n",
    "\n",
    "cen_inception_score = get_inception_score(centralized_gen_loader)\n",
    "print(cen_inception_score)\n",
    "(mean, std) = cen_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:57:12.502720Z",
     "start_time": "2023-05-12T06:56:29.118306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(63.7792, device='cuda:0')\n",
      "63.78\n"
     ]
    }
   ],
   "source": [
    "# test = get_fid_score(fedavg_gen_loader, centralized_gen_loader)\n",
    "# print(test)\n",
    "# print('{:.2f}'.format(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:15:23.892878Z",
     "start_time": "2023-05-12T06:14:53.760675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/diffusion_fedavg/sars_cov_2_ct_scan_b_0.5_c_10_le_5/generated_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:04<00:00,  5.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(134.9813, device='cuda:0')\n",
      "134.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.5971, device='cuda:0'), tensor(0.0326, device='cuda:0'))\n",
      "mean: 1.60, std: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "beta = 0.5                     # 5, 0.5, 0.1              \n",
    "num_clients = 10               # 10, 30, 50\n",
    "num_local_epochs = 5           # 1, 5, 10\n",
    "\n",
    "fedavg_gen_dir = os.path.join('./output/diffusion_fedavg/', '{}_b_{}_c_{}_le_{}'.format(dataset_name, beta, num_clients, num_local_epochs), 'generated_img')\n",
    "print(fedavg_gen_dir)\n",
    "fedavg_gen_data = ImgDataset(fedavg_gen_dir, transform=train_transform)\n",
    "fedavg_gen_loader = torch.utils.data.DataLoader(fedavg_gen_data, batch_size=batch_size, shuffle=False, num_workers=12, prefetch_factor=12)\n",
    "\n",
    "fedavg_train_fid_score = get_fid_score(train_loader, fedavg_gen_loader)\n",
    "print(fedavg_train_fid_score)\n",
    "print('{:.2f}'.format(fedavg_train_fid_score))\n",
    "\n",
    "fedavg_inception_score = get_inception_score(fedavg_gen_loader)\n",
    "print(fedavg_inception_score)\n",
    "(mean, std) = fedavg_inception_score\n",
    "print('mean: {:.2f}, std: {:.2f}'.format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T06:17:46.778680Z",
     "start_time": "2023-05-12T06:17:46.774670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedavg_gen_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
